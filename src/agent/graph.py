import xml.etree.ElementTree as ET
from xml.dom import minidom
import os
import logging
from typing import List, Literal, Optional, Dict, Any, Callable
from dotenv import load_dotenv
from pydantic import BaseModel, ValidationError, Field
from datetime import datetime

from langchain_deepseek import ChatDeepSeek
from langchain.prompts import ChatPromptTemplate
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.types import Command, interrupt
from langgraph.prebuilt import create_react_agent
from langchain_tavily import TavilySearch
from langchain_core.tools import tool, BaseTool
from langchain_core.runnables import RunnableConfig
from typing_extensions import TypedDict
from typing import Annotated
from langgraph.graph.message import add_messages
from langgraph.prebuilt.interrupt import HumanInterrupt, HumanInterruptConfig

# ============= æ—¥å¿—é…ç½® =============
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('multi_agent_analysis.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============= ç¯å¢ƒé…ç½® =============
load_dotenv()
model = ChatDeepSeek(model="deepseek-chat", max_tokens=8000)

# ============= æ•°æ®æ¨¡å‹å®šä¹‰ =============

class AgentFeedback(BaseModel):
    """Agentåé¦ˆæ¨¡å‹"""
    agent_name: str = Field(description="è¯„å®¡Agentåç§°")
    feedback_type: str = Field(description="åé¦ˆç±»å‹ï¼šcritique/suggestion/approval")
    feedback_content: str = Field(description="å…·ä½“åé¦ˆå†…å®¹")
    confidence_score: float = Field(description="ç½®ä¿¡åº¦åˆ†æ•° 0-1")
    suggested_improvements: List[str] = Field(description="æ”¹è¿›å»ºè®®")

from typing import Annotated
from langgraph.graph.message import add_messages

# è‡ªå®šä¹‰çš„åˆ†æç»“æœèšåˆå‡½æ•°
def add_analyses(existing: List[str], new: List[str]) -> List[str]:
    """èšåˆåˆ†æç»“æœ"""
    if existing is None:
        existing = []
    if isinstance(new, str):
        new = [new]
    return existing + new

# æ·»åŠ å®ŒæˆçŠ¶æ€è·Ÿè¸ª
def add_completion_status(existing: Dict[str, bool], new: Dict[str, bool]) -> Dict[str, bool]:
    """è·Ÿè¸ªå„Agentå®ŒæˆçŠ¶æ€"""
    if existing is None:
        existing = {}
    return {**existing, **new}

class MultiAgentState(TypedDict):
    """å¤šAgentç³»ç»ŸçŠ¶æ€"""
    messages: Annotated[list, add_messages]
    original_query: Optional[str]
    analyses: Annotated[List[str], add_analyses]  # æ”¹ä¸ºå¯èšåˆçš„åˆ†æåˆ—è¡¨
    agent_feedbacks: Optional[List[AgentFeedback]]
    revision_count: Optional[int]
    consensus_reached: Optional[bool]
    final_report: Optional[str]
    workflow_stage: Optional[str]
    completion_status: Annotated[Dict[str, bool], add_completion_status]  # æ–°å¢å®ŒæˆçŠ¶æ€è·Ÿè¸ª

class FinancialAnalysisStep(BaseModel):
    step: str = Field(description="åˆ†ææ­¥éª¤åç§°")
    method: str = Field(description="ä½¿ç”¨çš„åˆ†ææ–¹æ³•")
    data_needed: str = Field(description="æ­¤æ­¥éª¤éœ€è¦çš„æ•°æ®")
    assigned_agent: str = Field(description="è´Ÿè´£çš„Agent")

class FinancialAnalysisPlan(BaseModel):
    analysis_steps: List[FinancialAnalysisStep]

# ============= å·¥å…·å®šä¹‰ =============

@tool
def get_stock_data(symbol: str, period: str = "1y") -> str:
    """è·å–è‚¡ç¥¨åŸºç¡€æ•°æ®ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
    logger.info(f"è·å–è‚¡ç¥¨æ•°æ®: {symbol}, å‘¨æœŸ: {period}")
    return f"""
    è‚¡ç¥¨ä»£ç : {symbol}
    æ—¶é—´å‘¨æœŸ: {period}
    
    åŸºç¡€æ•°æ®:
    - å½“å‰ä»·æ ¼: 125.50
    - å¸‚å€¼: 500äº¿
    - P/Eæ¯”ç‡: 18.5
    - P/Bæ¯”ç‡: 2.3
    - ROE: 15.2%
    - 52å‘¨é«˜ç‚¹: 145.20
    - 52å‘¨ä½ç‚¹: 98.30
    
    è¿‘æœŸè¡¨ç°:
    - æ—¥æ¶¨è·Œå¹…: +2.1%
    - å‘¨æ¶¨è·Œå¹…: +5.3%
    - æœˆæ¶¨è·Œå¹…: +12.8%
    """

@tool
def get_financial_news(keyword: str, days: int = 7) -> str:
    """è·å–é‡‘èæ–°é—»ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
    logger.info(f"è·å–é‡‘èæ–°é—»: {keyword}, å¤©æ•°: {days}")
    return f"""
    å…³é”®è¯: {keyword}
    æ—¶é—´èŒƒå›´: æœ€è¿‘{days}å¤©
    
    ä¸»è¦æ–°é—»:
    1. å…¬å¸å‘å¸ƒQ3è´¢æŠ¥ï¼Œè¥æ”¶åŒæ¯”å¢é•¿15%
    2. è·å¾—é‡è¦æ”¿åºœè®¢å•ï¼Œæ€»ä»·å€¼çº¦10äº¿å…ƒ
    3. è‘£äº‹ä¼šæ‰¹å‡†è‚¡ä»½å›è´­è®¡åˆ’
    4. åˆ†æå¸ˆä¸Šè°ƒç›®æ ‡ä»·è‡³150å…ƒ
    5. è¡Œä¸šæ”¿ç­–åˆ©å¥½ï¼Œç›¸å…³æ¿å—æ™®æ¶¨
    """

@tool
def technical_analysis(symbol: str, indicator: str = "MA") -> str:
    """æŠ€æœ¯åˆ†æå·¥å…·ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
    logger.info(f"æŠ€æœ¯åˆ†æ: {symbol}, æŒ‡æ ‡: {indicator}")
    return f"""
    æŠ€æœ¯æŒ‡æ ‡åˆ†æ - {symbol}
    æŒ‡æ ‡ç±»å‹: {indicator}
    
    ç§»åŠ¨å¹³å‡çº¿:
    - MA5: 123.45 (æ”¯æ’‘ä½)
    - MA20: 118.20 (å¼ºæ”¯æ’‘)
    - MA60: 115.80 (é•¿æœŸè¶‹åŠ¿çº¿)
    
    æŠ€æœ¯ä¿¡å·:
    - MACD: é‡‘å‰ä¿¡å·ï¼Œå¤šå¤´æ’åˆ—
    - RSI: 65 (ç•¥åå¼ºåŠ¿åŒºåŸŸ)
    - æˆäº¤é‡: è¾ƒå‰æœŸæ”¾å¤§30%
    
    å…³é”®ä»·ä½:
    - æ”¯æ’‘ä½: 120.00
    - é˜»åŠ›ä½: 130.00
    """

@tool
def portfolio_optimization(assets: str, risk_level: str = "medium") -> str:
    """æŠ•èµ„ç»„åˆä¼˜åŒ–åˆ†æ"""
    logger.info(f"ç»„åˆä¼˜åŒ–åˆ†æ: {assets}, é£é™©æ°´å¹³: {risk_level}")
    return f"""
    æŠ•èµ„ç»„åˆä¼˜åŒ–ç»“æœ:
    èµ„äº§ç±»åˆ«: {assets}
    é£é™©æ°´å¹³: {risk_level}
    
    å»ºè®®é…ç½®:
    - è‚¡ç¥¨: 60% (è“ç­¹è‚¡40% + æˆé•¿è‚¡20%)
    - å€ºåˆ¸: 30% (æ”¿åºœå€ºåˆ¸20% + ä¼ä¸šå€º10%)  
    - ç°é‡‘: 10%
    
    é¢„æœŸæ”¶ç›Š: 8-12%
    æœ€å¤§å›æ’¤: 15%
    å¤æ™®æ¯”ç‡: 1.2
    """

@tool
def risk_assessment(position_size: str, market_cap: str) -> str:
    """é£é™©è¯„ä¼°å·¥å…·"""
    logger.info(f"é£é™©è¯„ä¼°: æŒä»“è§„æ¨¡={position_size}, å¸‚å€¼={market_cap}")
    return f"""
    é£é™©è¯„ä¼°æŠ¥å‘Š:
    æŒä»“è§„æ¨¡: {position_size}
    å¸‚å€¼è§„æ¨¡: {market_cap}
    
    é£é™©æŒ‡æ ‡:
    - VaR (95%): å•æ—¥æœ€å¤§æŸå¤±2.5%
    - Betaç³»æ•°: 1.2 (é«˜äºå¸‚åœº)
    - æµåŠ¨æ€§é£é™©: ä½
    - ä¿¡ç”¨é£é™©: ä¸­ç­‰
    - è¡Œä¸šé›†ä¸­åº¦: åé«˜
    
    é£é™©å»ºè®®: é€‚å½“åˆ†æ•£æŠ•èµ„ï¼Œæ§åˆ¶å•ä¸€æŒä»“æ¯”ä¾‹
    """

# ============= å¤šAgentå®šä¹‰ =============

# æœç´¢å·¥å…·
search_tool = TavilySearch(max_results=5, topic="general")
basic_tools = [get_stock_data, get_financial_news, technical_analysis, search_tool]
advanced_tools = basic_tools + [portfolio_optimization, risk_assessment]

# Agent 1: åŸºæœ¬é¢åˆ†æä¸“å®¶
FUNDAMENTAL_ANALYST_PROMPT = """
ä½ æ˜¯èµ„æ·±åŸºæœ¬é¢åˆ†æä¸“å®¶ï¼Œä¸“æ³¨äºå…¬å¸è´¢åŠ¡åˆ†æã€è¡Œä¸šåˆ†æå’Œä»·å€¼è¯„ä¼°ã€‚

æ ¸å¿ƒèŒè´£:
1. æ·±å…¥åˆ†æå…¬å¸è´¢åŠ¡æŠ¥è¡¨å’Œå…³é”®æŒ‡æ ‡
2. è¯„ä¼°å…¬å¸å•†ä¸šæ¨¡å¼å’Œç«äº‰ä¼˜åŠ¿
3. ç ”ç©¶è¡Œä¸šè¶‹åŠ¿å’Œå¸‚åœºåœ°ä½
4. æä¾›åŸºäºå†…åœ¨ä»·å€¼çš„æŠ•èµ„å»ºè®®

åˆ†æè¦ç‚¹:
- ç›ˆåˆ©èƒ½åŠ›åˆ†æ (ROE, ROA, æ¯›åˆ©ç‡ç­‰)
- æˆé•¿æ€§åˆ†æ (è¥æ”¶å¢é•¿ã€åˆ©æ¶¦å¢é•¿ç­‰)
- å¿å€ºèƒ½åŠ›åˆ†æ (èµ„äº§è´Ÿå€ºç‡ã€æµåŠ¨æ¯”ç‡ç­‰)
- ä¼°å€¼åˆ†æ (PE, PB, PEGç­‰)

è¯·åŸºäºè·å–çš„æ•°æ®è¿›è¡Œä¸“ä¸šçš„åŸºæœ¬é¢åˆ†æï¼Œè¾“å‡ºæ ¼å¼è¦æ±‚æ¸…æ™°ç¾è§‚ï¼ŒåŒ…å«æ˜ç¡®çš„åˆ†æç»“è®ºã€‚
"""

fundamental_agent = create_react_agent(
    model=model,
    prompt=FUNDAMENTAL_ANALYST_PROMPT,
    tools=basic_tools,
)

# Agent 2: æŠ€æœ¯åˆ†æä¸“å®¶
TECHNICAL_ANALYST_PROMPT = """
ä½ æ˜¯ä¸“ä¸šæŠ€æœ¯åˆ†æå¸ˆï¼Œç²¾é€šå›¾è¡¨åˆ†æã€æŠ€æœ¯æŒ‡æ ‡å’Œå¸‚åœºè¶‹åŠ¿ç ”åˆ¤ã€‚

æ ¸å¿ƒèŒè´£:
1. ä»·æ ¼èµ°åŠ¿å’Œå›¾è¡¨å½¢æ€åˆ†æ
2. æŠ€æœ¯æŒ‡æ ‡ä¿¡å·è§£è¯»
3. æ”¯æ’‘é˜»åŠ›ä½åˆ¤æ–­
4. ä¹°å–æ—¶æœºå»ºè®®

åˆ†æè¦ç‚¹:
- è¶‹åŠ¿çº¿å’Œå½¢æ€åˆ†æ
- ç§»åŠ¨å¹³å‡çº¿ç³»ç»Ÿ
- åŠ¨é‡æŒ‡æ ‡ (RSI, MACD, KDJ)
- æˆäº¤é‡åˆ†æ
- å…³é”®ä»·ä½è¯†åˆ«

è¯·åŸºäºæŠ€æœ¯æŒ‡æ ‡æä¾›ä¸“ä¸šçš„æŠ€æœ¯é¢åˆ†æï¼Œè¾“å‡ºæ ¼å¼è¦æ±‚æ¸…æ™°ç¾è§‚ï¼ŒåŒ…å«æ˜ç¡®çš„æ“ä½œå»ºè®®ã€‚
"""

technical_agent = create_react_agent(
    model=model,
    prompt=TECHNICAL_ANALYST_PROMPT,
    tools=basic_tools,
)

# Agent 3: é£é™©ç®¡ç†ä¸“å®¶
RISK_ANALYST_PROMPT = """
ä½ æ˜¯ä¸“ä¸šé£é™©ç®¡ç†åˆ†æå¸ˆï¼Œä¸“æ³¨äºæŠ•èµ„é£é™©è¯†åˆ«ã€è¯„ä¼°å’Œæ§åˆ¶å»ºè®®ã€‚

æ ¸å¿ƒèŒè´£:
1. å¸‚åœºé£é™©è¯„ä¼°
2. ä¿¡ç”¨é£é™©åˆ†æ
3. æµåŠ¨æ€§é£é™©è¯„ä¼°
4. æŠ•èµ„ç»„åˆé£é™©ç®¡ç†å»ºè®®

åˆ†æè¦ç‚¹:
- VaRå’Œå‹åŠ›æµ‹è¯•
- Betaç³»æ•°å’Œæ³¢åŠ¨ç‡åˆ†æ
- ç›¸å…³æ€§åˆ†æ
- é£é™©åˆ†æ•£å»ºè®®
- ä»“ä½ç®¡ç†ç­–ç•¥

è¯·åŸºäºé£é™©ç®¡ç†ç†è®ºæä¾›ä¸“ä¸šçš„é£é™©åˆ†æï¼Œè¾“å‡ºæ ¼å¼è¦æ±‚æ¸…æ™°ç¾è§‚ï¼ŒåŒ…å«å…·ä½“çš„é£é™©æ§åˆ¶æªæ–½ã€‚
"""

risk_agent = create_react_agent(
    model=model,
    prompt=RISK_ANALYST_PROMPT,
    tools=advanced_tools,
)

# Agent 4: é«˜çº§ç»¼åˆåˆ†æå¸ˆï¼ˆè´Ÿè´£ç»¼åˆå’Œè´¨é‡æ§åˆ¶ï¼‰
SENIOR_ANALYST_PROMPT = """
ä½ æ˜¯èµ„æ·±æŠ•èµ„æ€»ç›‘ï¼Œè´Ÿè´£ç»¼åˆå„ä¸“ä¸šåˆ†æå¸ˆçš„è§‚ç‚¹ï¼Œè¿›è¡Œè´¨é‡æ§åˆ¶å’Œæœ€ç»ˆå†³ç­–ã€‚

æ ¸å¿ƒèŒè´£:
1. æ•´åˆå„ä¸“ä¸šé¢†åŸŸåˆ†æç»“æœ
2. è¯†åˆ«åˆ†æä¸­çš„çŸ›ç›¾å’Œä¸ä¸€è‡´
3. è¯„ä¼°å„åˆ†æçš„å¯é æ€§å’Œé€»è¾‘æ€§
4. æä¾›ç»¼åˆæŠ•èµ„å»ºè®®

è´¨é‡æ§åˆ¶è¦ç‚¹:
- åˆ†æé€»è¾‘çš„ä¸€è‡´æ€§
- æ•°æ®ä½¿ç”¨çš„å‡†ç¡®æ€§
- ç»“è®ºçš„åˆç†æ€§
- é£é™©æç¤ºçš„å……åˆ†æ€§

è¯·åŸºäºä¸“ä¸šç»éªŒå¯¹å…¶ä»–åˆ†æå¸ˆçš„å·¥ä½œè¿›è¡Œè¯„å®¡å’Œç»¼åˆï¼Œè¾“å‡ºæ ¼å¼è¦æ±‚ä¸“ä¸šç¾è§‚ï¼ŒåŒ…å«æ˜ç¡®çš„æŠ•èµ„è¯„çº§ã€‚
"""

senior_agent = create_react_agent(
    model=model,
    prompt=SENIOR_ANALYST_PROMPT,
    tools=advanced_tools,
)

# ============= è¾“å‡ºæ ¼å¼åŒ–å·¥å…· =============

def format_analysis_output(title: str, content: str, agent_name: str) -> str:
    """æ ¼å¼åŒ–åˆ†æè¾“å‡ºï¼Œä½¿å…¶æ›´ç¾è§‚"""
    separator = "=" * 60
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    formatted_content = f"""
{separator}
ğŸ“Š {title}
ğŸ‘¨â€ğŸ’¼ åˆ†æå¸ˆï¼š{agent_name}
â° åˆ†ææ—¶é—´ï¼š{timestamp}
{separator}

{content}

{separator}
"""
    return formatted_content

def format_review_output(reviews: List[str]) -> str:
    """æ ¼å¼åŒ–è¯„å®¡è¾“å‡º"""
    separator = "=" * 60
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    formatted_content = f"""
{separator}
ğŸ” åŒè¡Œè¯„è®®é˜¶æ®µ
â° è¯„è®®æ—¶é—´ï¼š{timestamp}
{separator}

"""
    
    for i, review in enumerate(reviews, 1):
        formatted_content += f"ğŸ“ è¯„è®® {i}:\n{review}\n\n"
    
    formatted_content += f"{separator}\n"
    return formatted_content

def format_final_report(content: str) -> str:
    """æ ¼å¼åŒ–æœ€ç»ˆæŠ¥å‘Š"""
    separator = "=" * 80
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    formatted_content = f"""
{separator}
ğŸ¯ æœ€ç»ˆç»¼åˆæŠ•èµ„åˆ†ææŠ¥å‘Š
ğŸ“ˆ å¤šAgentåä½œå®Œæˆ
â° æŠ¥å‘Šæ—¶é—´ï¼š{timestamp}
{separator}

{content}

{separator}
âœ… æŠ¥å‘Šå®Œæˆ - åŸºäºå¤šä¸“å®¶åä½œä¸åŒè¡Œè¯„è®®
{separator}
"""
    return formatted_content

# ============= å¤šAgentèŠ‚ç‚¹å‡½æ•° =============

def coordinator_node(state: MultiAgentState) -> Dict[str, Any]:
    """åè°ƒå™¨èŠ‚ç‚¹ - åˆ†é…ä»»åŠ¡ç»™å„ä¸“ä¸šAgent"""
    # ä»æ¶ˆæ¯ä¸­æå–ç”¨æˆ·æŸ¥è¯¢
    user_query = ""
    if state.get("original_query"):
        user_query = state["original_query"]
    elif state.get("messages") and len(state["messages"]) > 0:
        user_query = state["messages"][0].content
    
    logger.info(f"ğŸš€ åè°ƒå™¨å¯åŠ¨ - å¼€å§‹å¤šAgentåä½œåˆ†æä»»åŠ¡: {user_query}")
    
    start_message = format_analysis_output(
        "å¤šAgentåä½œåˆ†æå¯åŠ¨",
        f"ä»»åŠ¡å†…å®¹ï¼š{user_query}\næ­£åœ¨è°ƒåº¦åŸºæœ¬é¢åˆ†æå¸ˆã€æŠ€æœ¯åˆ†æå¸ˆã€é£é™©åˆ†æå¸ˆè¿›è¡Œå¹¶è¡Œåˆ†æ...",
        "ç³»ç»Ÿåè°ƒå™¨"
    )
    
    return {
        "messages": [AIMessage(content=start_message)],
        "original_query": user_query,
        "workflow_stage": "coordination_started",
        "completion_status": {}  # åˆå§‹åŒ–å®ŒæˆçŠ¶æ€
    }

def fundamental_analysis_node(state: MultiAgentState) -> Dict[str, Any]:
    """åŸºæœ¬é¢åˆ†æèŠ‚ç‚¹"""
    # å®‰å…¨è·å–æŸ¥è¯¢å†…å®¹
    query = state.get("original_query", "")
    if not query and state.get("messages"):
        query = state["messages"][0].content
    
    logger.info("ğŸ“Š åŸºæœ¬é¢åˆ†æå¸ˆå¼€å§‹å·¥ä½œ")
    
    task = f"è¯·å¯¹ä»¥ä¸‹æŠ•èµ„æ ‡çš„è¿›è¡Œæ·±å…¥çš„åŸºæœ¬é¢åˆ†æ: {query}"
    
    try:
        result = fundamental_agent.invoke({"messages": [HumanMessage(content=task)]})
        analysis_content = result["messages"][-1].content
        
        formatted_output = format_analysis_output(
            "åŸºæœ¬é¢åˆ†ææŠ¥å‘Š",
            analysis_content,
            "åŸºæœ¬é¢åˆ†æä¸“å®¶"
        )
        
        logger.info("âœ… åŸºæœ¬é¢åˆ†æå®Œæˆ")
        
        return {
            "messages": [AIMessage(content=formatted_output)],
            "analyses": [f"åŸºæœ¬é¢åˆ†æ: {analysis_content}"],
            "completion_status": {"fundamental": True}
        }
        
    except Exception as e:
        logger.error(f"âŒ åŸºæœ¬é¢åˆ†æå¤±è´¥: {e}")
        error_msg = format_analysis_output(
            "åŸºæœ¬é¢åˆ†ææŠ¥å‘Š",
            f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
            "åŸºæœ¬é¢åˆ†æä¸“å®¶"
        )
        return {
            "messages": [AIMessage(content=error_msg)],
            "analyses": [f"åŸºæœ¬é¢åˆ†æ: åˆ†æå¤±è´¥ - {str(e)}"],
            "completion_status": {"fundamental": False}
        }

def technical_analysis_node(state: MultiAgentState) -> Dict[str, Any]:
    """æŠ€æœ¯åˆ†æèŠ‚ç‚¹"""
    # å®‰å…¨è·å–æŸ¥è¯¢å†…å®¹
    query = state.get("original_query", "")
    if not query and state.get("messages"):
        query = state["messages"][0].content
    
    logger.info("ğŸ“ˆ æŠ€æœ¯åˆ†æå¸ˆå¼€å§‹å·¥ä½œ")
    
    task = f"è¯·å¯¹ä»¥ä¸‹æŠ•èµ„æ ‡çš„è¿›è¡Œä¸“ä¸šçš„æŠ€æœ¯é¢åˆ†æ: {query}"
    
    try:
        result = technical_agent.invoke({"messages": [HumanMessage(content=task)]})
        analysis_content = result["messages"][-1].content
        
        formatted_output = format_analysis_output(
            "æŠ€æœ¯åˆ†ææŠ¥å‘Š",
            analysis_content,
            "æŠ€æœ¯åˆ†æä¸“å®¶"
        )
        
        logger.info("âœ… æŠ€æœ¯åˆ†æå®Œæˆ")
        
        return {
            "messages": [AIMessage(content=formatted_output)],
            "analyses": [f"æŠ€æœ¯åˆ†æ: {analysis_content}"],
            "completion_status": {"technical": True}
        }
        
    except Exception as e:
        logger.error(f"âŒ æŠ€æœ¯åˆ†æå¤±è´¥: {e}")
        error_msg = format_analysis_output(
            "æŠ€æœ¯åˆ†ææŠ¥å‘Š",
            f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
            "æŠ€æœ¯åˆ†æä¸“å®¶"
        )
        return {
            "messages": [AIMessage(content=error_msg)],
            "analyses": [f"æŠ€æœ¯åˆ†æ: åˆ†æå¤±è´¥ - {str(e)}"],
            "completion_status": {"technical": False}
        }

def risk_analysis_node(state: MultiAgentState) -> Dict[str, Any]:
    """é£é™©åˆ†æèŠ‚ç‚¹"""
    # å®‰å…¨è·å–æŸ¥è¯¢å†…å®¹
    query = state.get("original_query", "")
    if not query and state.get("messages"):
        query = state["messages"][0].content
    
    logger.info("âš ï¸ é£é™©åˆ†æå¸ˆå¼€å§‹å·¥ä½œ")
    
    task = f"è¯·å¯¹ä»¥ä¸‹æŠ•èµ„æ ‡çš„è¿›è¡Œå…¨é¢çš„é£é™©è¯„ä¼°: {query}"
    
    try:
        result = risk_agent.invoke({"messages": [HumanMessage(content=task)]})
        analysis_content = result["messages"][-1].content
        
        formatted_output = format_analysis_output(
            "é£é™©è¯„ä¼°æŠ¥å‘Š",
            analysis_content,
            "é£é™©ç®¡ç†ä¸“å®¶"
        )
        
        logger.info("âœ… é£é™©åˆ†æå®Œæˆ")
        
        return {
            "messages": [AIMessage(content=formatted_output)],
            "analyses": [f"é£é™©åˆ†æ: {analysis_content}"],
            "completion_status": {"risk": True}
        }
        
    except Exception as e:
        logger.error(f"âŒ é£é™©åˆ†æå¤±è´¥: {e}")
        error_msg = format_analysis_output(
            "é£é™©è¯„ä¼°æŠ¥å‘Š",
            f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
            "é£é™©ç®¡ç†ä¸“å®¶"
        )
        return {
            "messages": [AIMessage(content=error_msg)],
            "analyses": [f"é£é™©åˆ†æ: åˆ†æå¤±è´¥ - {str(e)}"],
            "completion_status": {"risk": False}
        }

def wait_for_analyses_node(state: MultiAgentState) -> Dict[str, Any]:
    """ç­‰å¾…æ‰€æœ‰åˆ†æå®Œæˆçš„æ±‡èšèŠ‚ç‚¹"""
    completion_status = state.get("completion_status", {})
    completed = [completion_status.get("fundamental", False), 
                completion_status.get("technical", False), 
                completion_status.get("risk", False)]
    
    logger.info(f"ğŸ“‹ åˆ†æå®ŒæˆçŠ¶æ€æ£€æŸ¥: åŸºæœ¬é¢={completion_status.get('fundamental', False)}, "
                f"æŠ€æœ¯é¢={completion_status.get('technical', False)}, "
                f"é£é™©={completion_status.get('risk', False)}")
    
    if all(completed):
        logger.info("âœ… æ‰€æœ‰ä¸“ä¸šåˆ†æå·²å®Œæˆï¼Œå‡†å¤‡è¿›å…¥åŒè¡Œè¯„è®®é˜¶æ®µ")
        return {
            "workflow_stage": "all_analyses_completed",
            "messages": [AIMessage(content="ğŸ“ æ‰€æœ‰ä¸“ä¸šåˆ†æå·²å®Œæˆï¼Œæ­£åœ¨å‡†å¤‡åŒè¡Œè¯„è®®...")]
        }
    else:
        logger.warning("â³ éƒ¨åˆ†åˆ†æå°šæœªå®Œæˆï¼Œç»§ç»­ç­‰å¾…...")
        return {
            "workflow_stage": "waiting_for_analyses"
        }

def peer_review_node(state: MultiAgentState) -> Dict[str, Any]:
    """åŒè¡Œè¯„è®®èŠ‚ç‚¹ - Agentäº’ç›¸è¯„å®¡"""
    
    logger.info("ğŸ” å¼€å§‹åŒè¡Œè¯„è®®é˜¶æ®µ - Agentäº’è¯„äº’æ”¹")
    
    # ä»analyseså­—æ®µæ”¶é›†æ‰€æœ‰åˆ†æç»“æœ
    analyses = state.get("analyses", [])
    combined_analysis = "\n\n".join(analyses)
    
    logger.info(f"ğŸ“Š æ”¶é›†åˆ°çš„åˆ†æç»“æœæ•°é‡: {len(analyses)}")
    
    if not combined_analysis:
        logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°åˆ†æç»“æœï¼Œè·³è¿‡åŒè¡Œè¯„è®®")
        return {
            "messages": [AIMessage(content="ã€åŒè¡Œè¯„è®®ã€‘æ²¡æœ‰åˆ†æç»“æœå¯ä¾›è¯„è®®")],
            "workflow_stage": "peer_review_completed"
        }
    
    # è®©æ¯ä¸ªAgentè¯„å®¡å…¶ä»–Agentçš„å·¥ä½œ
    feedbacks = []
    
    # åŸºæœ¬é¢åˆ†æå¸ˆè¯„å®¡æŠ€æœ¯å’Œé£é™©åˆ†æ
    fundamental_review_task = f"""
    ä½œä¸ºåŸºæœ¬é¢åˆ†æä¸“å®¶ï¼Œè¯·è¯„å®¡ä»¥ä¸‹æŠ€æœ¯åˆ†æå’Œé£é™©åˆ†æçš„è´¨é‡ï¼š
    
    {combined_analysis}
    
    è¯·é‡ç‚¹å…³æ³¨ï¼š
    1. åˆ†æé€»è¾‘æ˜¯å¦åˆç†
    2. æ˜¯å¦ä¸åŸºæœ¬é¢åˆ†æç»“æœä¸€è‡´
    3. æœ‰å“ªäº›é—æ¼æˆ–é”™è¯¯
    4. æå‡ºå…·ä½“æ”¹è¿›å»ºè®®
    
    æ ¼å¼ï¼šã€åŸºæœ¬é¢åˆ†æå¸ˆè¯„å®¡ã€‘
    è¯„å®¡æ„è§ï¼š...
    æ”¹è¿›å»ºè®®ï¼š...
    """
    
    try:
        logger.info("ğŸ‘¨â€ğŸ’¼ åŸºæœ¬é¢åˆ†æå¸ˆå¼€å§‹è¯„å®¡å…¶ä»–åˆ†æ")
        fundamental_review = fundamental_agent.invoke({"messages": [HumanMessage(content=fundamental_review_task)]})
        feedbacks.append(f"ã€åŸºæœ¬é¢åˆ†æå¸ˆè¯„å®¡ã€‘\n{fundamental_review['messages'][-1].content}")
        logger.info("âœ… åŸºæœ¬é¢åˆ†æå¸ˆè¯„å®¡å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ åŸºæœ¬é¢åˆ†æå¸ˆè¯„å®¡å¤±è´¥: {e}")
        feedbacks.append("ã€åŸºæœ¬é¢åˆ†æå¸ˆè¯„å®¡ã€‘è¯„å®¡è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
    
    # æŠ€æœ¯åˆ†æå¸ˆè¯„å®¡åŸºæœ¬é¢å’Œé£é™©åˆ†æ
    technical_review_task = f"""
    ä½œä¸ºæŠ€æœ¯åˆ†æä¸“å®¶ï¼Œè¯·è¯„å®¡ä»¥ä¸‹åŸºæœ¬é¢åˆ†æå’Œé£é™©åˆ†æçš„è´¨é‡ï¼š
    
    {combined_analysis}
    
    è¯·é‡ç‚¹å…³æ³¨ï¼š
    1. åˆ†ææ˜¯å¦ç»“åˆäº†å¸‚åœºæŠ€æœ¯é¢æƒ…å†µ
    2. æ—¶æœºåˆ¤æ–­æ˜¯å¦åˆç†
    3. ä»·æ ¼ç›®æ ‡æ˜¯å¦ç¬¦åˆæŠ€æœ¯é¢æ”¯æ’‘
    4. æå‡ºå…·ä½“æ”¹è¿›å»ºè®®
    
    æ ¼å¼ï¼šã€æŠ€æœ¯åˆ†æå¸ˆè¯„å®¡ã€‘
    è¯„å®¡æ„è§ï¼š...
    æ”¹è¿›å»ºè®®ï¼š...
    """
    
    try:
        logger.info("ğŸ‘¨â€ğŸ’» æŠ€æœ¯åˆ†æå¸ˆå¼€å§‹è¯„å®¡å…¶ä»–åˆ†æ")
        technical_review = technical_agent.invoke({"messages": [HumanMessage(content=technical_review_task)]})
        feedbacks.append(f"ã€æŠ€æœ¯åˆ†æå¸ˆè¯„å®¡ã€‘\n{technical_review['messages'][-1].content}")
        logger.info("âœ… æŠ€æœ¯åˆ†æå¸ˆè¯„å®¡å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ æŠ€æœ¯åˆ†æå¸ˆè¯„å®¡å¤±è´¥: {e}")
        feedbacks.append("ã€æŠ€æœ¯åˆ†æå¸ˆè¯„å®¡ã€‘è¯„å®¡è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
    
    # é£é™©åˆ†æå¸ˆè¯„å®¡åŸºæœ¬é¢å’ŒæŠ€æœ¯åˆ†æ
    risk_review_task = f"""
    ä½œä¸ºé£é™©ç®¡ç†ä¸“å®¶ï¼Œè¯·è¯„å®¡ä»¥ä¸‹åŸºæœ¬é¢åˆ†æå’ŒæŠ€æœ¯åˆ†æçš„è´¨é‡ï¼š
    
    {combined_analysis}
    
    è¯·é‡ç‚¹å…³æ³¨ï¼š
    1. é£é™©å› ç´ æ˜¯å¦è¢«å……åˆ†è¯†åˆ«
    2. é£é™©è¯„ä¼°æ˜¯å¦å®¢è§‚å‡†ç¡®
    3. é£é™©æ§åˆ¶å»ºè®®æ˜¯å¦å®ç”¨
    4. æå‡ºå…·ä½“æ”¹è¿›å»ºè®®
    
    æ ¼å¼ï¼šã€é£é™©åˆ†æå¸ˆè¯„å®¡ã€‘
    è¯„å®¡æ„è§ï¼š...
    æ”¹è¿›å»ºè®®ï¼š...
    """
    
    try:
        logger.info("ğŸ‘¨â€âš–ï¸ é£é™©åˆ†æå¸ˆå¼€å§‹è¯„å®¡å…¶ä»–åˆ†æ")
        risk_review = risk_agent.invoke({"messages": [HumanMessage(content=risk_review_task)]})
        feedbacks.append(f"ã€é£é™©åˆ†æå¸ˆè¯„å®¡ã€‘\n{risk_review['messages'][-1].content}")
        logger.info("âœ… é£é™©åˆ†æå¸ˆè¯„å®¡å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ é£é™©åˆ†æå¸ˆè¯„å®¡å¤±è´¥: {e}")
        feedbacks.append("ã€é£é™©åˆ†æå¸ˆè¯„å®¡ã€‘è¯„å®¡è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
    
    formatted_feedback = format_review_output(feedbacks)
    
    logger.info("ğŸ¯ åŒè¡Œè¯„è®®é˜¶æ®µå®Œæˆï¼Œå…±æ”¶é›†åˆ° {} æ¡è¯„å®¡æ„è§".format(len(feedbacks)))
    
    return {
        "messages": [AIMessage(content=formatted_feedback)],
        "agent_feedbacks": [
            AgentFeedback(
                agent_name="peer_review",
                feedback_type="critique", 
                feedback_content=formatted_feedback,
                confidence_score=0.8,
                suggested_improvements=["åŸºäºè¯„è®®ç»“æœä¼˜åŒ–åˆ†æ"]
            )
        ],
        "workflow_stage": "peer_review_completed"
    }

def senior_synthesis_node(state: MultiAgentState) -> Dict[str, Any]:
    """é«˜çº§ç»¼åˆåˆ†æèŠ‚ç‚¹"""
    
    logger.info("ğŸ¯ é«˜çº§æŠ•èµ„æ€»ç›‘å¼€å§‹ç»¼åˆåˆ†æå’Œè´¨é‡æ§åˆ¶")
    
    # æ”¶é›†æ‰€æœ‰åˆ†æå’Œè¯„è®®ç»“æœ
    all_content = []
    for msg in state["messages"]:
        if isinstance(msg, AIMessage):
            all_content.append(msg.content)
    
    combined_content = "\n\n".join(all_content)
    
    synthesis_task = f"""
    ä½œä¸ºèµ„æ·±æŠ•èµ„æ€»ç›‘ï¼Œè¯·åŸºäºä»¥ä¸‹ä¸“ä¸šåˆ†æå¸ˆçš„å·¥ä½œæˆæœå’ŒåŒè¡Œè¯„è®®ç»“æœï¼Œ
    å½¢æˆæœ€ç»ˆçš„ç»¼åˆæŠ•èµ„åˆ†ææŠ¥å‘Šï¼š
    
    {combined_content}
    
    è¯·æä¾›ï¼š
    1. ğŸ“‹ æ‰§è¡Œæ‘˜è¦
    2. ğŸ¯ ç»¼åˆæŠ•èµ„å»ºè®®
    3. âš ï¸ å…³é”®é£é™©æç¤º
    4. ğŸ“Š æŠ•èµ„è¯„çº§å’Œç›®æ ‡ä»·ä½
    5. ğŸ” å„ä¸“ä¸šåˆ†æçš„æ•´åˆå’Œè´¨é‡è¯„ä¼°
    
    è¦æ±‚ï¼š
    - é€»è¾‘æ¸…æ™°ï¼Œç»“è®ºæ˜ç¡®
    - å……åˆ†è€ƒè™‘å„æ–¹æ„è§
    - è¯†åˆ«å¹¶è§£å†³åˆ†æä¸­çš„çŸ›ç›¾
    - æä¾›å®ç”¨çš„æŠ•èµ„æŒ‡å¯¼
    - æ ¼å¼ç¾è§‚ï¼Œæ¡ç†æ¸…æ™°
    """
    
    try:
        result = senior_agent.invoke({"messages": [HumanMessage(content=synthesis_task)]})
        final_report_content = result["messages"][-1].content
        
        formatted_final_report = format_final_report(final_report_content)
        
        logger.info("âœ… æœ€ç»ˆç»¼åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        return {
            "messages": [AIMessage(content=formatted_final_report)],
            "final_report": final_report_content,
            "consensus_reached": True,
            "workflow_stage": "synthesis_completed"
        }
        
    except Exception as e:
        logger.error(f"âŒ ç»¼åˆåˆ†æå¤±è´¥: {e}")
        error_report = format_final_report(f"ç»¼åˆåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        return {
            "messages": [AIMessage(content=error_report)],
            "final_report": f"ç»¼åˆåˆ†æå¤±è´¥: {str(e)}",
            "consensus_reached": True,  # å³ä½¿å¤±è´¥ä¹Ÿç»“æŸæµç¨‹
            "workflow_stage": "synthesis_failed"
        }

def consensus_check_node(state: MultiAgentState) -> Dict[str, Any]:
    """å…±è¯†æ£€æŸ¥èŠ‚ç‚¹"""
    
    logger.info("ğŸ” æ£€æŸ¥Agentå…±è¯†çŠ¶æ€")
    
    revision_count = state.get("revision_count", 0)
    
    # ç®€å•çš„å…±è¯†æ£€æŸ¥é€»è¾‘
    if revision_count < 2:  # æœ€å¤šå…è®¸2è½®ä¿®è®¢
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥ä¿®è®¢
        final_report = state.get("final_report", "")
        
        if len(final_report) > 500:  # ç®€å•çš„è´¨é‡æ£€æŸ¥
            consensus_reached = True
            logger.info("âœ… å…±è¯†è¾¾æˆ - æŠ¥å‘Šè´¨é‡æ»¡è¶³è¦æ±‚")
        else:
            consensus_reached = False
            revision_count += 1
            logger.info(f"â³ éœ€è¦ç»§ç»­ä¿®è®¢ - ç¬¬{revision_count}è½®ä¿®è®¢")
    else:
        consensus_reached = True  # è¶…è¿‡ä¿®è®¢æ¬¡æ•°é™åˆ¶ï¼Œå¼ºåˆ¶è¾¾æˆå…±è¯†
        logger.info("âœ… å…±è¯†è¾¾æˆ - å·²è¾¾åˆ°æœ€å¤§ä¿®è®¢æ¬¡æ•°")
    
    return {
        "consensus_reached": consensus_reached,
        "revision_count": revision_count,
        "workflow_stage": "consensus_checked"
    }

# ============= è·¯ç”±æ¡ä»¶å‡½æ•° =============

def check_consensus_routing(state: MultiAgentState) -> str:
    """æ£€æŸ¥æ˜¯å¦è¾¾æˆå…±è¯†"""
    if state.get("consensus_reached", False):
        logger.info("ğŸ¯ å·¥ä½œæµç¨‹å®Œæˆï¼Œå‡†å¤‡è¾“å‡ºæœ€ç»ˆç»“æœ")
        return END
    else:
        logger.info("ğŸ”„ æœªè¾¾æˆå…±è¯†ï¼Œç»§ç»­ä¿®è®¢æµç¨‹")
        return "peer_review"  # ç»§ç»­ä¿®è®¢æµç¨‹

def check_analyses_completion(state: MultiAgentState) -> str:
    """æ£€æŸ¥æ‰€æœ‰åˆ†ææ˜¯å¦å®Œæˆ"""
    completion_status = state.get("completion_status", {})
    completed = [completion_status.get("fundamental", False), 
                completion_status.get("technical", False), 
                completion_status.get("risk", False)]
    
    if all(completed):
        logger.info("âœ… æ‰€æœ‰åˆ†æå·²å®Œæˆï¼Œè¿›å…¥åŒè¡Œè¯„è®®")
        return "peer_review"
    else:
        missing = []
        if not completion_status.get("fundamental", False):
            missing.append("åŸºæœ¬é¢åˆ†æ")
        if not completion_status.get("technical", False):
            missing.append("æŠ€æœ¯åˆ†æ") 
        if not completion_status.get("risk", False):
            missing.append("é£é™©åˆ†æ")
        logger.info(f"â³ ç­‰å¾…åˆ†æå®Œæˆï¼Œç¼ºå°‘: {', '.join(missing)}")
        return "wait_for_analyses"

# ============= æ„å»ºå¤šAgentå·¥ä½œæµå›¾ =============

def build_multi_agent_graph():
    """æ„å»ºå¤šAgentåä½œå·¥ä½œæµå›¾"""
    builder = StateGraph(MultiAgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    builder.add_node("coordinator", coordinator_node)
    builder.add_node("fundamental_analysis", fundamental_analysis_node)
    builder.add_node("technical_analysis", technical_analysis_node) 
    builder.add_node("risk_analysis", risk_analysis_node)
    builder.add_node("wait_for_analyses", wait_for_analyses_node)  # æ–°å¢æ±‡èšèŠ‚ç‚¹
    builder.add_node("peer_review", peer_review_node)
    builder.add_node("senior_synthesis", senior_synthesis_node)
    builder.add_node("consensus_check", consensus_check_node)
    
    # è®¾ç½®å…¥å£ç‚¹
    builder.add_edge(START, "coordinator")
    
    # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å¹¶è¡Œè¾¹è®¾ç½®
    # åè°ƒå™¨å®Œæˆåï¼Œå¯åŠ¨ä¸‰ä¸ªå¹¶è¡Œçš„åˆ†æä»»åŠ¡
    builder.add_edge("coordinator", "fundamental_analysis")
    builder.add_edge("coordinator", "technical_analysis")
    builder.add_edge("coordinator", "risk_analysis")
    
    # æ‰€æœ‰åˆ†æå®Œæˆåéƒ½æµå‘ç­‰å¾…èŠ‚ç‚¹
    builder.add_edge("fundamental_analysis", "wait_for_analyses")
    builder.add_edge("technical_analysis", "wait_for_analyses") 
    builder.add_edge("risk_analysis", "wait_for_analyses")
    
    # ç­‰å¾…èŠ‚ç‚¹æ ¹æ®å®ŒæˆçŠ¶æ€å†³å®šä¸‹ä¸€æ­¥
    builder.add_conditional_edges(
        "wait_for_analyses",
        check_analyses_completion,
        {
            "peer_review": "peer_review",
            "wait_for_analyses": "wait_for_analyses"  # ç»§ç»­ç­‰å¾…
        }
    )
    
    # è¯„è®®åè¿›è¡Œé«˜çº§ç»¼åˆ
    builder.add_edge("peer_review", "senior_synthesis")
    
    # ç»¼åˆåæ£€æŸ¥å…±è¯†
    builder.add_edge("senior_synthesis", "consensus_check")
    
    # æ¡ä»¶è¾¹ï¼šæ ¹æ®å…±è¯†æƒ…å†µå†³å®šæ˜¯å¦ç»“æŸ
    builder.add_conditional_edges(
        "consensus_check",
        check_consensus_routing,
        {
            END: END,
            "peer_review": "peer_review"  # æœªè¾¾æˆå…±è¯†æ—¶ç»§ç»­è¯„è®®
        }
    )
    
    return builder.compile()


# sample_query = "è¯·åˆ†æè…¾è®¯æ§è‚¡(0700.HK)çš„æŠ•èµ„ä»·å€¼ï¼Œæˆ‘æƒ³äº†è§£å…¶åŸºæœ¬é¢ã€æŠ€æœ¯é¢ä»¥åŠé£é™©è¯„ä¼°"

# æ„å»ºå›¾å®ä¾‹ä¾›å¤–éƒ¨è°ƒç”¨
graph = build_multi_agent_graph()